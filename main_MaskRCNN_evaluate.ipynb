{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Segmentation evaluation\n",
    "\n",
    "Test a Detector on A Customized Dataset (Mask RCNN)\n",
    "\n",
    "Notice: MMDetection **only support evaluating mask AP of dataset in COCO format for now**. Other methods and more advanced usages can be found in the [doc](https://mmdetection.readthedocs.io/en/latest/tutorials/customize_dataset.html). So we need to reorganize the dataset into a COCO format firstly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model architecture\n",
    "\n",
    "Notice: The .py file (model config file) is generated in the \"main_InstanceSeg_train.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmcv import Config\n",
    "from mmengine.config import Config, DictAction\n",
    "\n",
    "# load a model architecture\n",
    "model_file=r'/scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/Pollutant_yolact_r50.py'\n",
    "cfg = Config.fromfile(model_file)\n",
    "\n",
    "# print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights from checkpoint file (.pth)\n",
    "\n",
    "# checkpoint_file = r\"F:\\Tianlong\\PythonProject\\deep_plastic_MMDetection\\checkpoints\\train_weights/train1_100_epochs/best_bbox_mAP_epoch_48.pth\"\n",
    "checkpoint_file = r\"/scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/best_coco_segm_mAP_50_epoch_43.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "\n",
    "# (1) GPU device\n",
    "model = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# (2) cpu device\n",
    "# model = init_detector(cfg, checkpoint_file, device='cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Test on a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-gpu testing\n",
    "\n",
    "# \"--show-dir\" saves the predicted images in test dataset\n",
    "# \"test_evaluator.outfile_prefix\": saves the test results in a \"pkl\" file, this file can be used to predict images\n",
    "\n",
    "!python tools/test.py \\\n",
    "    checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/Pollutant_yolact_r50.py \\\n",
    "    /scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/best_coco_segm_mAP_50_epoch_43.pth \\\n",
    "    --work-dir /scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/test/ \\\n",
    "    --out /scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/test/result.pkl\n",
    "    # --cfg-options \\\n",
    "    # --show-dir /scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper2_exp5/Oos_20per/FRCNN_Frozen_4_PreTrain_GV/pred_images_in_test_dataset/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Predict images in a folder\n",
    "\n",
    "Note: inference_detector only supports single-image inference for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old version\n",
    "# import os\n",
    "\n",
    "# # test images in a folder\n",
    "# folder_path = r\"/scratch/tjian/Data/Pollutant/test/\"\n",
    "# out_path = r\"/scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/test/ima_pred/\"\n",
    "\n",
    "# file_names = os.listdir(folder_path)\n",
    "# for filename in file_names:\n",
    "#         if filename.endswith('.jpg'):\n",
    "#             image_path = os.path.join(folder_path, filename)\n",
    "#             result = inference_detector(model, image_path)\n",
    "#             print(result)\n",
    "#             # or save the visualization results to image files\n",
    "#             out_file_name= os.path.join(out_path, filename)\n",
    "#             model.show_result(image_path, \n",
    "#                               result, \n",
    "#                               score_thr=0.5,\n",
    "#                               out_file=out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.utils import register_all_modules\n",
    "from mmdet.registry import VISUALIZERS\n",
    "import mmcv\n",
    "\n",
    "config_file =r'/scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/Pollutant_yolact_r50.py'\n",
    "checkpoint_file = r\"/scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/best_coco_segm_mAP_50_epoch_43.pth\"\n",
    "\n",
    "#Register all modules in mmdet into the registries\n",
    "register_all_modules()\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')  # or device='cpu'\n",
    "\n",
    "\n",
    "# test images in a folder\n",
    "folder_path = r\"/scratch/tjian/Data/Pollutant/test/\"\n",
    "out_path = r\"/scratch/tjian/PythonProject/DP_MMDetection/checkpoints/train_weights/Paper_Peng/Yolact_r50/lr_0.001/test/ima_pred/\"\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "for filename in file_names:\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            img = mmcv.imread(image_path, channel_order='rgb')\n",
    "            result = inference_detector(model, img)\n",
    "            # print(result)\n",
    "            \n",
    "            # init the visualizer(execute this block only once)\n",
    "            visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "            # the dataset_meta is loaded from the checkpoint and\n",
    "            # then pass to the model in init_detector\n",
    "            visualizer.dataset_meta = model.dataset_meta\n",
    "            \n",
    "            out_file_name= os.path.join(out_path, filename)\n",
    "            # show the results\n",
    "            visualizer.add_datasample('result',\n",
    "                                      img,\n",
    "                                      data_sample=result,\n",
    "                                      draw_gt=False,\n",
    "                                      wait_time=0,\n",
    "                                      out_file=out_file_name,\n",
    "                                      pred_score_thr=0.5\n",
    "                                      )\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/analysis_tools/confusion_matrix.py \\\n",
    "    configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco_Pollutant.py \\\n",
    "    F:/Tianlong/PythonProject/deep_plastic_MMDetection/checkpoints/train_weights/train1_300_epochs_v4/test/output.pkl \\\n",
    "    F:/Tianlong/PythonProject/deep_plastic_MMDetection/checkpoints/train_weights/train1_300_epochs_v4/test \\\n",
    "    --show \\\n",
    "    --score-thr 0.5 \\\n",
    "    --tp-iou-thr 0.5 \n",
    "    \n",
    "    \n",
    "# ${CONFIG}  ${DETECTION_RESULTS}  ${SAVE_DIR} --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Predict images in a folder and save bbox and segm in an excel file\n",
    "\n",
    "(Only windows system)\n",
    "\n",
    "Note:\n",
    "\n",
    "(1) define excel path in untils.bbox_segm.py\n",
    "\n",
    "(2) define source image folder below\n",
    "\n",
    "(3) saving results in excel only works on Windows system \n",
    "\n",
    "(4) Two folders will be generated in \"--out-dir\", including (1) predicted images, and (2) bbox and mask info in json file (mask info is encoded)\n",
    "\n",
    "(5) I mainly modify the \"/mmdet/apis/det_inferencer.py\" to realize this function, referring: https://blog.csdn.net/m0_46246301/article/details/130561039\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: checkpoints/best_coco_segm_mAP_50_epoch_43.pth\n",
      "['entrap bean', 'free bean']\n",
      "09/25 23:31:19 - mmengine - WARNING - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n",
      "reading image:  C:/Users/tjian/Desktop/1/A10.jpg\n",
      "reading image:  C:/Users/tjian/Desktop/1/A11.jpg\n",
      "reading image:  C:/Users/tjian/Desktop/1/A9.jpg\n",
      "Inference ---------------------------------------- 0.0 it/s  \n",
      "results have been saved at C:/Users/tjian/Desktop/2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjian\\Anaconda3\\envs\\MMDetection\\lib\\site-packages\\mmengine\\visualization\\visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "!python demo/image_demo.py C:/Users/tjian/Desktop/1/ \\\n",
    "    checkpoints/Pollutant_yolact_r50.py \\\n",
    "    --weights checkpoints/best_coco_segm_mAP_50_epoch_43.pth \\\n",
    "    --out-dir C:/Users/tjian/Desktop/2/ \\\n",
    "    --pred-score-thr 0.5 \\\n",
    "    --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version\n",
    "\n",
    "import os\n",
    "import pycocotools.mask as mask_util\n",
    "import utils.bbox_segm as bs\n",
    "from mmdet.core import encode_mask_results\n",
    "from utils.polygonFromMask import polygonFromMask\n",
    "\n",
    "num_classes = 2\n",
    "classes_labels = [\"entrap_bean\", \"free_bean\"]\n",
    "score_thr = 0.5\n",
    "\n",
    "# test images in a folder\n",
    "folder_path = r\"U:\\AIMMW\\Tianlong\\Pollutant\\dataset\\v2\\test\"\n",
    "out_path = r\"U:\\AIMMW\\Tianlong\\Pollutant\\dataset\\v2\\test_result\\test_pred\"\n",
    "\n",
    "# create the \"out_path\" if they do not exist\n",
    "if not os.path.isdir(out_path):\n",
    "    os.mkdir(out_path)\n",
    "\n",
    "# save results in an excel file\n",
    "excel_path = r\"U:\\AIMMW\\Tianlong\\Pollutant\\dataset\\v2\\test_result\\test_pred.xlsx\"\n",
    "\n",
    "filename_list=[]\n",
    "xmin_list=[]\n",
    "ymin_list=[]\n",
    "xmax_list=[]\n",
    "ymax_list=[]\n",
    "conf_list=[]\n",
    "class_bbox_list=[]\n",
    "area_bbox_list=[]\n",
    "area_mask_list=[]\n",
    "# index_list=[]\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "for filename in file_names:\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        result = inference_detector(model, image_path)\n",
    "        # print(\"result:\", result)\n",
    "        # or save the visualization results to image files\n",
    "        out_file_name= os.path.join(out_path, filename)\n",
    "        model.show_result(image_path, \n",
    "                          result, \n",
    "                          score_thr=0.5,\n",
    "                          out_file=out_file_name)\n",
    "            \n",
    "        ## bbox -> result[0] and mask -> result[1] for single image\n",
    "        encode_result = (result[0], encode_mask_results(result[1])) # containing bbox and segm\n",
    "        bbox_results, segm_results = encode_result\n",
    "        # print(bbox_results)\n",
    "\n",
    "        for i in range(num_classes):\n",
    "          # print(classes_labels[i], \":\")\n",
    "          \n",
    "          j=0\n",
    "          index_list=[]\n",
    "          \n",
    "          for bbox_result in bbox_results[i]:\n",
    "              conf = bbox_result[4]\n",
    "               \n",
    "              # only save bbox and segm with the confidence (>score_thr)\n",
    "              if conf >= score_thr:\n",
    "                xmin = bbox_result[0]\n",
    "                ymin = bbox_result[1]\n",
    "                xmax = bbox_result[2]\n",
    "                ymax = bbox_result[3]\n",
    "                conf = bbox_result[4]\n",
    "                class_bbox = classes_labels[i]\n",
    "                area_bbox = (xmax-xmin)*(ymax-ymin) \n",
    "                index = j\n",
    "                # print(\"j: \", j)\n",
    "              \n",
    "                filename_list.append(filename)\n",
    "                xmin_list.append(xmin)\n",
    "                ymin_list.append(ymin)\n",
    "                xmax_list.append(xmax)\n",
    "                ymax_list.append(ymax)\n",
    "                conf_list.append(conf)\n",
    "                class_bbox_list.append(class_bbox)\n",
    "                area_bbox_list.append(area_bbox)\n",
    "                index_list.append(j)\n",
    "\n",
    "              j=j+1\n",
    "\n",
    "          for index_seg in index_list:\n",
    "            segm_result=segm_results[i][index_seg]\n",
    "            #  print(\"##: \",segm_result)\n",
    "            sample_mask = mask_util.decode(segm_result)\n",
    "            sample_polygon,_,AreaMask = polygonFromMask(sample_mask)\n",
    "            \n",
    "            area_mask_list.append(AreaMask)\n",
    "            # print(\"area:\", AreaMask)\n",
    "\n",
    "\n",
    "bs.save_bbox_info_in_excel(excel_path, \"Sheet1\", filename_list, \n",
    "         xmin_list, ymin_list, xmax_list, ymax_list, conf_list, class_bbox_list, area_bbox_list, area_mask_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
